{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story arcs:\n",
      "1. The Hero's Journey\n",
      "2. Rags to Riches\n",
      "3. Overcoming the Monster\n",
      "4. The Quest\n",
      "5. Voyage and Return\n",
      "6. Rebirth/Transformation\n",
      "7\n",
      "\n",
      "\n",
      "Randomly selected arc:\n",
      "2. Rags to Riches\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def openaiCompletionArcs(parameters):\n",
    "    # load environment variables from .env file\n",
    "    load_dotenv('.secrets.env')\n",
    "    # set API key from environment variable\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    # call the OpenAI API to generate the list of story arcs\n",
    "    response = openai.Completion.create(\n",
    "        **parameters\n",
    "    )\n",
    "\n",
    "    # extract the list of story arcs from the API response\n",
    "    story_arcs = [arc.strip() for arc in response.choices[0].text.split(\"\\n\") if arc.strip()]\n",
    "\n",
    "    # pick a random story arc and store it as a variable\n",
    "    random_arc = random.choice(story_arcs)\n",
    "\n",
    "    return story_arcs, random_arc\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    \"model\": \"text-davinci-003\",\n",
    "    \"prompt\": \"List classic story arcs in fiction.\",\n",
    "    \"temperature\": 0, # 0 means no randomness 1 means completely random\n",
    "    \"max_tokens\": 50, # max number of tokens to generate\n",
    "    \"top_p\": 1, # 1 means no filtering, 0 means only the most likely token`\n",
    "    \"frequency_penalty\": 1, # 0 means no penalty, 1 means penalize new tokens based on their existing frequency\n",
    "    \"presence_penalty\": 1 # 0 means no penalty, 1 means penalize new tokens based on whether they appear in the prompt\n",
    "}\n",
    "\n",
    "# parameters = {\n",
    "#     \"model\": \"text-davinci-003\",\n",
    "#     \"prompt\": \"List classic story arcs in fiction.\",\n",
    "#     \"temperature\": 0,\n",
    "#     \"max_tokens\": 150,\n",
    "#     \"top_p\": 1,\n",
    "#     \"frequency_penalty\": 1,\n",
    "#     \"presence_penalty\": 1\n",
    "# }\n",
    "\n",
    "story_arcs, random_arc = openaiCompletionArcs(parameters)\n",
    "print(\"Story arcs:\")\n",
    "print(\"\\n\".join(story_arcs))\n",
    "print('\\n')\n",
    "print(\"Randomly selected arc:\")\n",
    "print(random_arc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Rags to Riches\n",
      "[{'role': 'assistant', 'content': 'As I sit here in my aged study, surrounded by musty tomes and ancient artifacts, I cannot help but feel a sense of unease. The world around us is an ever-shifting, ever-changing place, and yet there are those who cling to the past, to the forgotten and the forbidden.\\n\\nI have delved deep into the mysteries of the universe, seeking to uncover the secrets that lie hidden beneath the surface of our reality. I have seen things that would drive a lesser man to madness, and yet I am still here, still searching, still striving to unlock the secrets of the cosmos.\\n\\nBut there are forces at work in the world that seek to keep us in the dark, to prevent us from seeing the truth. Dark and ancient powers that lurk in the shadows, waiting to strike at any moment.\\n\\nI have seen the horrors that these forces can unleash, and I have felt their icy grip upon my soul. But still I press on, driven by a need to know, to understand, to unravel the mysteries of the universe.\\n\\nFor in the end, it is not wealth or power that drives me, but the unquenchable thirst for knowledge, for understanding, for the truth that lies hidden in the darkness. And I will not rest until I have uncovered every last secret, unlocked every last door, and peered into the very heart of the unknown.'}, {'role': 'assistant', 'content': 'For it is only then that I will truly know what it means to be alive, to feel the pulse of the universe as it beats within my soul.\\n\\nAnd so I continue my journey, my quest for knowledge, my search for the truth. No matter the cost, no matter the danger, I will press on, for in the end, the reward will be worth the price.\\n\\nFor there is nothing more precious than knowledge, nothing more valuable than understanding, and nothing more powerful than the truth. And it is in these things that I find my purpose, my reason for being, and my very salvation in a world ruled by darkness and deceit.\\n\\nSo let the world tremble before me, let the shadows quake in fear, for I will not be swayed or deterred from my path. For I am the seeker, the explorer, the adventurer, and the revealer of secrets. And nothing, not even the darkness itself, can stand in my way.'}, {'role': 'assistant', 'content': 'For I am the light that shines in the darkness, the beacon of hope in a world of despair. And as long as there is breath in my body and fire in my soul, I will continue to seek, to discover, and to reveal the hidden truths of the universe.\\n\\nFor it is only through our understanding of the unknown that we can truly embrace the wonder and majesty of existence. And it is only through our pursuit of knowledge that we can unlock the doors to our own destiny, and unleash the power of the human spirit to soar to new heights of greatness and glory.'}]\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Create a variable to store the chat history\n",
    "chat_history = []\n",
    "\n",
    "# Define a function to generate a response to a prompt\n",
    "\n",
    "def first_chat_request_response():\n",
    "    # load environment variables from .env file\n",
    "    load_dotenv('.secrets.env')\n",
    "    # set API key from environment variable\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    # Define the model name\n",
    "    MODEL = \"gpt-3.5-turbo\"\n",
    "    # Define the content to start the prompt\n",
    "    CONTENT = f\"You are a novelist writing in the {random_arc} arc style.\"\n",
    "    # Define the prompt\n",
    "    PROMPT = f\"Write in the style of HP Lovecraft.\"\n",
    "    # Example OpenAI Python library request\n",
    "    response = openai.ChatCompletion.create(model=MODEL, messages=[{\"role\": \"system\", \"content\": CONTENT}, {\n",
    "                                            \"role\": \"user\", \"content\": PROMPT}], temperature=0.6)\n",
    "    # Get the message object from the first choice\n",
    "    message = response[\"choices\"][0][\"message\"]\n",
    "    # Format the message content as a dictionary\n",
    "    message_content = {\"role\": message[\"role\"], \"content\": message[\"content\"]}\n",
    "    # Append the message content to the chat history\n",
    "    chat_history.append(message_content)\n",
    "\n",
    "# Define a function to generate a response to a prompt\n",
    "\n",
    "\n",
    "def subsequent_chat_request_response():\n",
    "    # Example OpenAI Python library request\n",
    "    MODEL = \"gpt-3.5-turbo\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=MODEL,\n",
    "        messages=chat_history,\n",
    "        temperature=0.9,\n",
    "    )\n",
    "    # Get the message object from the first choice\n",
    "    message = response[\"choices\"][0][\"message\"]\n",
    "    # Format the message content as a dictionary\n",
    "    message_content = {\"role\": message[\"role\"], \"content\": message[\"content\"]}\n",
    "    # Append the message content to the chat history\n",
    "    chat_history.append(message_content)\n",
    "\n",
    "\n",
    "# Call the function to start the chat\n",
    "first_chat_request_response()\n",
    "\n",
    "# Call the function to generate a followup response\n",
    "subsequent_chat_request_response()\n",
    "\n",
    "# Call the function to generate a followup response\n",
    "subsequent_chat_request_response()\n",
    "\n",
    "\n",
    "print(random_arc)\n",
    "print(chat_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def summonCthulu():\n",
    "#     # load environment variables from .env file\n",
    "#     load_dotenv('.secrets.env')\n",
    "#     # set API key from environment variable\n",
    "#     openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "#     # Define the model name\n",
    "#     MODEL = \"gpt-3.5-turbo\"\n",
    "#     # Define the content to start the prompt\n",
    "#     CONTENT = f\"You are a novelist writing in the {random_arc} arc style.\"\n",
    "#     # Define the prompt\n",
    "#     PROMPT = f\"Write in the style of HP Lovecraft.\"\n",
    "#     # Example OpenAI Python library request\n",
    "#     response = openai.ChatCompletion.create(model=MODEL, messages=[{\"role\": \"system\", \"content\": CONTENT}, {\n",
    "#                                             \"role\": \"user\", \"content\": PROMPT}], temperature=0.6)\n",
    "#     # Get the message object from the first choice\n",
    "#     message = response[\"choices\"][0][\"message\"]\n",
    "#     # Format the message content as a dictionary\n",
    "#     message_content = {\"role\": message[\"role\"], \"content\": message[\"content\"]}\n",
    "#     # Append the message content to the chat history\n",
    "#     chat_history.append(message_content)\n",
    "#     # Example OpenAI Python library request\n",
    "#     MODEL = \"gpt-3.5-turbo\"\n",
    "#     response = openai.ChatCompletion.create(\n",
    "#         model=MODEL,\n",
    "#         messages=chat_history,\n",
    "#         temperature=0,\n",
    "#     )\n",
    "\n",
    "#     # Get the message object from the first choice\n",
    "#     message = response[\"choices\"][0][\"message\"]\n",
    "#     # Format the message content as a dictionary\n",
    "#     message_content = {\"role\": message[\"role\"], \"content\": message[\"content\"]}\n",
    "#     # Append the message content to the chat history\n",
    "#     chat_history.append(random_arc)\n",
    "#     chat_history.append(message_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(chat_history)):\n",
    "#     print(chat_history[i]['content'])\n",
    "\n",
    "# Define the chat history as a string\n",
    "chat_history_html = ''\n",
    "for message in chat_history:\n",
    "    chat_history_html += f'<p class=\"message\"><span class=\"role\">{message[\"role\"]}:</span> {message[\"content\"]}</p>\\n'\n",
    "\n",
    "# Open index.html file in append mode\n",
    "with open('index.html', 'a') as f:\n",
    "    # Replace the comment with the chat history text using string formatting\n",
    "    f.write(random_arc)\n",
    "    f.write('<div id=\"chat-history\">\\n')\n",
    "    f.write(chat_history_html)\n",
    "    f.write('</div>\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
